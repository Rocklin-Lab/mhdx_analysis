{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "'''\n",
    "# Required input files\n",
    "\n",
    "1) deduplicated.json # The file containing the deduplicated dataset\n",
    "\n",
    "    This is generated as a final output from hxrate_pipeline (https://github.com/Rocklin-Lab/hdxrate_pipeline)\n",
    "\n",
    "2) hbonds.json # The file containing the hydrogen bonds dataset. It should also contain a PF column speficying the protein family of the protein (HHH, EEHEE, etc.)\n",
    "\n",
    "    This can be generated using the script pdb2hbonds.py available at `mhdx_analysis/scripts/pdb2hbonds.py`. This script will generate one file per protein structure which should be concatenated in one final dataframe to be loaded in this notebook.\n",
    "    We are interested in the expected number of N-H predicted to be protected in each protein structure, n_hb_bb_all.\n",
    "    PF column should be added to the final dataframe.\n",
    "    \n",
    "'''"
   ],
   "id": "67be5bb143e37100"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T16:30:25.446190Z",
     "start_time": "2025-02-07T16:30:25.437622Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ],
   "id": "ffaaae8c10d318b6",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "f_hx = 'deduplicated.json'\n",
    "f_hb = 'hbonds.json'\n",
    "\n",
    "\n",
    "output_param_table = \"../results/param_table.json\"\n",
    "\n",
    "output_df = \"../results/df_cooperativities.json\""
   ],
   "id": "6ab57c25ee2974c1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_hx = pd.read_json(f_hx)\n",
    "df_hbonds = pd.read_json(f_hb)"
   ],
   "id": "5673b7742e93822e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = pd.merge(df_hx, df_hbonds[[\"sequence\", \"n_hb_bb_all\", \"PF\"]], \n",
    "                     left_on=[\"sequence\"], right_on=[\"sequence\"],how=\"left\")"
   ],
   "id": "21af0c537df88b76"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Populate dataframe with important metrics\n",
    "\n",
    "df[\"free_energy\"] = df[\"free_energy\"].apply(lambda x: sorted(x, reverse=True)).values\n",
    "\n",
    "# Count number of exchangable residues (len(seq) - 2 - n_P)\n",
    "df[\"n_exch_res\"] = df[\"free_energy\"].apply(lambda x: len(x))\n",
    "\n",
    "\n",
    "def sum_over_threshold(x, threshold=2):\n",
    "    x = np.array(x)\n",
    "    x = x - threshold\n",
    "    x = x[x > 0]\n",
    "    return np.sum(x)\n",
    "\n",
    "df[\"free_energy_integrated\"] = df.apply(lambda x: np.sum(x[\"free_energy\"]), axis=1)\n",
    "df[\"free_energy_integrated_per_res\"] = df[\"free_energy_integrated_0\"] / df[\"n_exch_res\"]\n",
    "df[\"free_energy_integrated_measurable_per_hb\"] = df[\"free_energy_integrated_measurable\"] / df[\"n_hb_bb_all\"]\n",
    "\n",
    "df[\"ratio_n_hb_n_exch\"] = df[\"n_hb_bb_all\"] / df[\"n_exch_res\"]\n",
    "df[\"ratio_n_measurable_obs_rates_n_exch\"] = df[\"n_measurable_obs_rates\"] / df[\"n_exch_res\"]\n",
    "df['ratio_n_measurable_intrinsic_rates_n_exch'] = df['n_measurable_intrinsic_rates']/ df['n_exch_res']\n"
   ],
   "id": "7d0ada0418561a79"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Implement 4-param model to derive cooperativities",
   "id": "7ba087d3a3d4a3c9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.infer import MCMC, NUTS, Predictive\n",
    "import jax.numpy, jax.scipy\n",
    "from jax import random\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import json\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ],
   "id": "4cf975d189a1a5b3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def summary_plots(model_name, df, label='0'):\n",
    "    \n",
    "    print(model_name, label)\n",
    "    \n",
    "    def add_pearson(x, y, ax):\n",
    "        pc = pearsonr(df[x], df[y])[0]\n",
    "        ax.text(0.01, 0.9, f\"PC: {pc:.3f}\", transform=ax.transAxes, size=18)\n",
    "        \n",
    "    \n",
    "    sns.clustermap(\n",
    "    df[[f\"free_energy_integrated_per_hb\", f\"free_energy_integrated_per_res\", model_name + \"_pred\"]].corr(),\n",
    "    annot=True)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    fig, ax = plt.subplots(2, 3, figsize=(15, 8), constrained_layout=True)\n",
    "    \n",
    "    ax = ax.flatten()\n",
    "\n",
    "    ax[0].scatter(df[model_name+'_pred'],df[f'free_energy_integrated_per_res'],label=model_name,alpha=0.2,s=10)\n",
    "    ax[0].set_xlabel('predicted_int_fe_per_res')\n",
    "    ax[0].set_ylabel('int_fe_per_res')\n",
    "    ax[0].grid()\n",
    "    ax[0].plot([0,5],[0,5],color='black')\n",
    "    ax[0].set_title('%s corr %.3f %.3f' % (model_name, \n",
    "                                      df[f'free_energy_integrated_per_res'].corr(df[model_name+'_pred']), \n",
    "                                      mean_squared_error(df[f'free_energy_integrated_per_res'], df[model_name+'_pred'])**0.5 \n",
    "                                     )\n",
    "                   )\n",
    "\n",
    "    sns.regplot(df, x='dg_mean',y=model_name + '_residual',label=model_name,scatter_kws={'alpha':0.1,'s':10},line_kws={'color':'black'},lowess=True, ax=ax[1])\n",
    "\n",
    "    \n",
    "    add_pearson(x='dg_mean',y=model_name + '_residual', ax=ax[1])\n",
    "    \n",
    "    ax[1].grid()\n",
    "    ax[1].set_ylim(-1,1)\n",
    "    \n",
    "    \n",
    "    sns.regplot(df, x='ratio_n_hb_n_exch',y=model_name + '_residual',label=model_name,scatter_kws={'alpha':0.1,'s':10},line_kws={'color':'black'},lowess=True, ax=ax[2])\n",
    "    \n",
    "    add_pearson(x='ratio_n_hb_n_exch',y=model_name + '_residual', ax=ax[2])\n",
    "    ax[2].grid()\n",
    "    ax[2].set_ylim(-1,1)\n",
    "    \n",
    "    sns.regplot(df, x='ratio_n_measurable_obs_rates_n_exch',y=model_name + '_residual',label=model_name,scatter_kws={'alpha':0.1,'s':10},line_kws={'color':'black'},lowess=True, ax=ax[3])\n",
    "    add_pearson(x='ratio_n_measurable_obs_rates_n_exch',y=model_name + '_residual', ax=ax[3])\n",
    "    ax[3].grid()\n",
    "    ax[3].set_ylim(-1,1)\n",
    "    \n",
    "    sns.regplot(df, x='ratio_n_measurable_intrinsic_rates_n_exch',y=model_name + '_residual',label=model_name,scatter_kws={'alpha':0.1,'s':10},line_kws={'color':'black'},lowess=True, ax=ax[4])\n",
    "    add_pearson(x='ratio_n_measurable_intrinsic_rates_n_exch',y=model_name + '_residual', ax=ax[4])\n",
    "    ax[4].grid()\n",
    "    ax[4].set_ylim(-1,1)\n",
    "    \n",
    "    sns.regplot(df, x='netcharge',y=model_name + '_residual',label=model_name,scatter_kws={'alpha':0.1,'s':10},line_kws={'color':'black'},lowess=True, ax=ax[5])\n",
    "    add_pearson(x='netcharge',y=model_name + '_residual', ax=ax[5])\n",
    "    ax[5].grid()\n",
    "    ax[5].set_ylim(-1,1)\n",
    "\n",
    " \n",
    "    plt.show()\n",
    "    "
   ],
   "id": "866e0abc43da9973"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def fit_4_param(dg_mean, fxn_hb,  netcharge, free_energy_integrated_per_res=None):\n",
    "    \n",
    "    dg_mean = jax.numpy.array(dg_mean)   \n",
    "    fxn_hb = jax.numpy.array(fxn_hb)\n",
    "\n",
    "    sigma=numpyro.sample(\"sigma\", dist.Exponential(1))\n",
    "    \n",
    "    log_scaling_exp=numpyro.sample(\"log_scaling_exp\", dist.Normal(-0.3,2))\n",
    "    scaling_exp = numpyro.deterministic(\"scaling_exp\", jax.numpy.exp(log_scaling_exp))\n",
    "    \n",
    "    log_hb_exp=numpyro.sample(\"log_hb_exp\", dist.Normal(-0.3,2))\n",
    "    hb_exp = numpyro.deterministic(\"hb_exp\", jax.numpy.exp(log_hb_exp))\n",
    "    \n",
    "    offset=numpyro.sample(\"offset\", dist.Normal(0,5))\n",
    "    \n",
    "    scaling_factor_dg=numpyro.sample(\"scaling_factor_dg\", dist.Normal(1,3))\n",
    "\n",
    "    \n",
    "    scaling_factor_nc=numpyro.sample(\"scaling_factor_nc\", dist.Normal(-1,3))\n",
    "    \n",
    "    pred_free_energy_integrated_per_res = scaling_factor_dg * jax.numpy.power(dg_mean-offset,scaling_exp) * jax.numpy.power(fxn_hb,hb_exp) + scaling_factor_nc * netcharge\n",
    "    \n",
    "    numpyro.sample(\"obs\", dist.Normal(pred_free_energy_integrated_per_res, sigma), obs=free_energy_integrated_per_res)\n",
    "    "
   ],
   "id": "97514e92c92c6c13"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Subset used to derive cooperativities\n",
    "\n",
    "query = \"group in ['group_1: measurable unmerged','group_2: measurable merged'] & dg_mean > 2\"\n",
    "\n",
    "df_subset = df.query(query).reset_index(drop=True)"
   ],
   "id": "5abd70c92ec1b14b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Fit model using all data\n",
    "\n",
    "model_name = f\"fit\"\n",
    "\n",
    "model = fit_4_param\n",
    "mcmc = MCMC(NUTS(model), num_warmup=1000, num_samples=1000, num_chains=1)\n",
    "mcmc.run(random.PRNGKey(0), df_subset['dg_mean'].values, df_subset['ratio_n_hb_n_exch'].values, df_subset['netcharge'].values, df_subset[f'free_energy_integrated_per_res'].values)\n",
    "mcmc.print_summary(exclude_deterministic=False)\n",
    "\n",
    "\n",
    "predictive = Predictive(model, mcmc.get_samples())\n",
    "predictions = predictive(random.PRNGKey(1), df['dg_mean'].values, df['ratio_n_hb_n_exch'].values, df['netcharge'].values)\n",
    "df[model_name+'_pred'] = predictions['obs'].mean(axis=0)\n",
    "df[model_name+'_pred_std'] = predictions['obs'].std(axis=0)\n",
    "\n",
    "\n",
    "df[model_name + '_residual'] = df[f'free_energy_integrated_per_res'] - df[model_name+'_pred']\n",
    "\n",
    "print(model_name, mean_squared_error(df.query(query)[f'free_energy_integrated_per_res'],\n",
    "                                     df.query(query)[model_name+'_pred']))\n",
    "\n",
    "\n",
    "summary_plots(f'fit', df.query(query))"
   ],
   "id": "610310ecc860270a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "models = [f'fit']\n",
    "param_table = []\n",
    "for model_name in models:\n",
    "    print (model_name)\n",
    "    for pf in list(df['PF'].unique()) + ['all']:\n",
    "        print(pf)\n",
    "        if pf == 'all':\n",
    "            subdf = df.query(query)\n",
    "        else:\n",
    "            subdf = df.query(f\"PF == @pf & {query}\")\n",
    "        if len(subdf) < 50: continue\n",
    "        model = fit_4_param\n",
    "        mcmc = MCMC(NUTS(model), num_warmup=1000, num_samples=1000, num_chains=1)\n",
    "        mcmc.run(random.PRNGKey(0), subdf['dg_mean'].values, subdf['ratio_n_hb_n_exch'].values, subdf['netcharge'].values, subdf[f'free_energy_integrated_per_res'].values)\n",
    "        #add parameter values to param_table\n",
    "        param_table.append([model_name, pf, \n",
    "                            float(mcmc.get_samples()['sigma'].mean()),\n",
    "                            float(mcmc.get_samples()['offset'].mean()),\n",
    "                            float(mcmc.get_samples()['scaling_exp'].mean()),\n",
    "                            float(mcmc.get_samples()['scaling_factor_dg'].mean()),\n",
    "                            float(mcmc.get_samples()['scaling_factor_nc'].mean()),\n",
    "                            float(mcmc.get_samples()['hb_exp'].mean()),\n",
    "                           ])\n",
    "        #get predictions\n",
    "        predictive = Predictive(model, mcmc.get_samples())\n",
    "        predictions = predictive(random.PRNGKey(1), subdf['dg_mean'].values, subdf['ratio_n_hb_n_exch'].values, subdf['netcharge'].values)['obs'].mean(axis=0)\n",
    "        param_table[-1].append(np.corrcoef(subdf[f'free_energy_integrated_per_res'],predictions)[0,1])\n",
    "        param_table[-1].append(np.corrcoef(subdf[f'free_energy_integrated_per_res'],subdf[model_name+'_pred'])[0,1])\n",
    "        param_table[-1].append(mean_squared_error(subdf[f'free_energy_integrated_per_res'],predictions)**0.5)\n",
    "        param_table[-1].append(mean_squared_error(subdf[f'free_energy_integrated_per_res'],subdf[model_name+'_pred'])**0.5)\n",
    "\n",
    "param_table = pd.DataFrame(param_table, columns=['model','PF','sigma','offset','scaling_exp','scaling_factor_dg','scaling_factor_nc', 'hb_exp','pf_corr','global_corr','pf_rmse','global_rmse'])\n",
    "\n",
    "\n",
    "if not os.path.isdir(os.path.dirname(output_param_table)):\n",
    "    os.makedirs(os.path.dirname(output_param_table))\n",
    "\n",
    "param_table.to_json(output_param_table)"
   ],
   "id": "5ea49b575459c4fe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Use param_table to derive cooperativity",
   "id": "b7648ad53567dce3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def apply_param_table_to_filtered_data(df_, param_table, query=\"group in ['group_1: measurable unmerged','group_2: measurable merged'] & dg_mean > 2\"):\n",
    "    \n",
    "    model = param_table.model.iloc[0]    \n",
    "    \n",
    "    # Initialize dictionary to store model terms\n",
    "    fit_model_terms = {}\n",
    "\n",
    "    # Populate fit_model_terms based on unique protein families (PF)\n",
    "    for pf in param_table['PF'].unique():\n",
    "        subdf = df_.query(f\"PF == @pf & {query}\")\n",
    "        # Extract parameters from param_table\n",
    "        params = param_table.query('PF == @pf').iloc[0]\n",
    "        fit_model_terms[pf] = {\n",
    "            'offset': params['offset'],\n",
    "            'scaling_exp': params['scaling_exp'],\n",
    "            'scaling_factor_dg': params['scaling_factor_dg'],\n",
    "            'scaling_factor_nc': params['scaling_factor_nc'],\n",
    "            'hb_exp': params['hb_exp']\n",
    "        }\n",
    "\n",
    "    # Add 'all' parameters as default for missing PFs\n",
    "    for pf in df_['PF'].unique():\n",
    "        if pf not in fit_model_terms:\n",
    "            fit_model_terms[pf] = fit_model_terms['all']\n",
    "\n",
    "    # Apply calculations for each row in df_\n",
    "    def calculate_fit_pred_pf(row):\n",
    "        pf_terms = fit_model_terms[row['PF']]\n",
    "        return float(\n",
    "            pf_terms['scaling_factor_dg'] * jnp.power(row['dg_mean'] - pf_terms['offset'], pf_terms['scaling_exp']) *\n",
    "            jnp.power(row['ratio_n_hb_n_exch'], pf_terms['hb_exp']) + pf_terms['scaling_factor_nc'] * row['netcharge']\n",
    "        )\n",
    "\n",
    "    def calculate_fit_pred(row):\n",
    "        all_terms = fit_model_terms['all']\n",
    "        return float(\n",
    "            all_terms['scaling_factor_dg'] * jnp.power(row['dg_mean'] - all_terms['offset'], all_terms['scaling_exp']) *\n",
    "            jnp.power(row['ratio_n_hb_n_exch'], all_terms['hb_exp']) + all_terms['scaling_factor_nc'] * row['netcharge']\n",
    "        )\n",
    "\n",
    "    # Calculate 'fit_pred_pf' and 'fit_pred'\n",
    "    df_[f'{model}_pred_pf'] = df_.apply(calculate_fit_pred_pf, axis=1)\n",
    "    df_[f'{model}_pred'] = df_.apply(calculate_fit_pred, axis=1)\n",
    "\n",
    "    # Calculate cooperativity models\n",
    "    df_[f'cooperativity_model_pf'] = df_[f'free_energy_integrated_per_res'] - df_[f'{model}_pred_pf']\n",
    "    df_[f'cooperativity_model_global'] = df_[f'free_energy_integrated_per_res'] - df_[f'{model}_pred']\n",
    "\n",
    "    return df_"
   ],
   "id": "2de0d6999802242a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df = apply_param_table_to_filtered_data(df, param_table)",
   "id": "87924b63c2dbcd14"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Derive normalized cooperativities dictionary\n",
    "\n",
    "combined_dict_file = '../results/cooperativity_std_mean_dict.json'\n",
    "\n",
    "\n",
    "if not os.path.isfile(combined_dict_file):\n",
    "    \n",
    "    # Calculate std and mean for cooperativity_model_pf grouped by PF\n",
    "    std_pf = df.query(query).groupby('PF')[f'cooperativity_model_pf'].std().to_dict()\n",
    "    mean_pf = df.query(query).groupby('PF')[f'cooperativity_model_pf'].mean().to_dict()\n",
    "    \n",
    "    # Create a dictionary for each label with std and mean for each PF\n",
    "    label_dict = {pf: {f'std': std_pf[pf], f'mean': mean_pf[pf]} for pf in std_pf}\n",
    "    \n",
    "    # Calculate global std and mean for cooperativity_model_global\n",
    "    global_std = df.query(query)[f'cooperativity_model_global'].std()\n",
    "    global_mean = df.query(query)[f'cooperativity_model_global'].mean()\n",
    "    \n",
    "    # Add global statistics to the label-specific dictionary\n",
    "    label_dict['global'] = {f'std': global_std, f'mean': global_mean}\n",
    "    \n",
    "    # Add this label-specific dictionary to the main combined dictionary\n",
    "    combined_dict = label_dict\n",
    "    \n",
    "    # Save the entire combined dictionary as a JSON file\n",
    "    with open(combined_dict_file, 'w') as json_file:\n",
    "        json.dump(combined_dict, json_file, indent=4)  # indent=4 for pretty printing\n",
    "\n",
    "else:\n",
    "    # Load the dictionary from the JSON file if it already exists\n",
    "    with open(combined_dict_file, 'r') as json_file:\n",
    "        combined_dict = json.load(json_file)"
   ],
   "id": "35ba99aa7c9807d9"
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": "### Compute normalized cooperativities (normalized_cooperativity_model_pf: Family-normalized cooperativity and normalized_cooperativity_model_global: Normalized cooperativity)",
   "id": "fb4fb7312069760f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Normalizing 'cooperativity_model_pf' by PF\n",
    "pf_column = f'cooperativity_model_pf'\n",
    "normalized_pf_column = f'normalized_cooperativity_model_pf'\n",
    "\n",
    "df[normalized_pf_column] = df.apply(\n",
    "    lambda x: (\n",
    "        (x[pf_column] - combined_dict[x['PF']][f'mean']) / combined_dict[x['PF']][f'std']\n",
    "        if x['PF'] in combined_dict and combined_dict[x['PF']][f'std'] != 0\n",
    "        else x[pf_column]  # Fall back to unnormalized value if std is 0\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "\n",
    "# Normalizing 'cooperativity_model_global'\n",
    "global_column = f'cooperativity_model_global'\n",
    "normalized_global_column = f'normalized_cooperativity_model_global'\n",
    "\n",
    "global_mean = combined_dict['global'][f'mean']\n",
    "global_std = combined_dict['global'][f'std']\n",
    "\n",
    "df[normalized_global_column] = df[global_column].apply(\n",
    "    lambda x: (x - global_mean) / global_std if global_std != 0 else x\n",
    ")\n"
   ],
   "id": "31be32e6234c92b6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Apply final quality filter to remove outliers\n",
    "\n",
    "query = \"group in ['group_1: measurable unmerged','group_2: measurable merged'] & dg_mean > 2 & ((-3 < normalized_cooperativity_model_global < 3) | (-3 < normalized_cooperativity_model_pf < 3))\"\n",
    "\n",
    "df = df.query(query).reset_index(drop=True)"
   ],
   "id": "dfce154843aba840"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Save final dataframe with cooperativities\n",
    "\n",
    "if not os.path.isdir(os.path.dirname(output_df)):\n",
    "    os.makedirs(os.path.dirname(output_df))\n",
    "\n",
    "param_table.to_json(output_df)"
   ],
   "id": "89913345bc8ad2fc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
